1.	采用numpy的正态分布生成D1D2两个样本集，存在D1.txt D2.txt中。
2.	使用knn算法，计算出每个点与目标点的距离，储存在一个heapq中，求出最小的k个点并计算其点数最多的类别。
K=3	P=0.94
K=7	P=0.94
K=9	P=0.9467
可以发现k=3时准确率已经足够高，而当k提高，准确率变化的程度很小。这是因为数据过于密集，而且是线性不可分的，所以实际上k对分类效果影响很小。
3.	使用Ho-Kashyap算法，计算出Y矩阵，再迭代求出增广权向量a。将增广的特征向量与权向量相乘求出g(x)，先区分w1和w2w3，再区分w2和w3。在一次线性分类器下，P=0.9467
4.	对二次分类器，我分别尝试增加平方项、增加交叉项、同时增加平方项与交叉项三种算法，发现准确率分别为0.94,0.93,0.9367。
可以发现，使用二次分类器反而没有线性分类器的结果好。我分析这是因为数据是线性不可分的，在二次分类器下也不可分。而且可以发现a在二次项的系数与一次项相比较小，说明由于数据分布较为密集，二次分类器并相比一次分类器没有明显的改变。而使用平方项比交叉项效果略好，但是程度不明显。
